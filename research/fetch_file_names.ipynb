{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "import os\n",
    "url: str = os.environ.get(\"URL\")\n",
    "key: str = os.environ.get(\"ANON_KEY\")\n",
    "supabase: Client = create_client(url, \"sb_secret__hURMlWV0e8lHlKreudFAA_UBScLp6U\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://s3.amazonaws.com/tripdata/index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://s3.amazonaws.com/tripdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.raise_for_status()  # Ensure we notice bad responses\n",
    "soup = BeautifulSoup(response.text, 'xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_citibike_xml_to_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m current_files \u001b[38;5;241m=\u001b[39m \u001b[43mparse_citibike_xml_to_df\u001b[49m(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_citibike_xml_to_df' is not defined"
     ]
    }
   ],
   "source": [
    "current_files = parse_citibike_xml_to_df(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m json_str \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_files\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mto_json(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m, date_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miso\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m files_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json_str)\n\u001b[1;32m      3\u001b[0m supabase\u001b[38;5;241m.\u001b[39mtable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_files\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mupsert(files_data, on_conflict\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mexecute()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'current_files' is not defined"
     ]
    }
   ],
   "source": [
    "json_str = current_files.head(10).to_json(orient=\"records\", date_format='iso')\n",
    "files_data = json.loads(json_str)\n",
    "supabase.table('processed_files').upsert(files_data, on_conflict='file_name').execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = supabase.table(\"processed_files\").select(\"*\").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_files = pd.DataFrame(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_new_files(live_files, prev_files):\n",
    "    # Method 1: Using merge with indicator\n",
    "    merged = live_files.merge(\n",
    "        prev_files,\n",
    "        on=\"file_name\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"_new\", \"_old\"),\n",
    "        indicator=True,\n",
    "    )\n",
    "\n",
    "    # Filter for rows that either:\n",
    "    # 1) Don't appear in old_df (_merge == 'left_only')\n",
    "    # 2) Appear in old_df but have newer last_modified date\n",
    "    filtered_df = merged[\n",
    "        (merged[\"_merge\"] == \"left_only\")  # Not in old_df\n",
    "        | (\n",
    "            merged[\"last_modified_new\"] > merged[\"last_modified_old\"]\n",
    "        )  # Newer modification date\n",
    "    ][[\"file_name\", \"last_modified_new\"]].rename(\n",
    "        columns={\"last_modified_new\": \"last_modified\"}\n",
    "    )\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfiltered_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_df' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_processed_files():\n",
    "    result = supabase.table(\"processed_files\").select(\"*\").execute()\n",
    "    prev_files = pd.DataFrame(result.data)\n",
    "    return prev_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_live_files():\n",
    "    response = requests.get(\"https://s3.amazonaws.com/tripdata\")\n",
    "    response.raise_for_status()  # Ensure we notice bad responses\n",
    "    current_files = parse_citibike_xml_to_df(response.text)\n",
    "    return current_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unprocessed_files():\n",
    "    prev_files = get_prev_processed_files()\n",
    "    # Files live on the website.\n",
    "    live_files = get_live_files()\n",
    "    # Get new files which have not been processed.\n",
    "    new_files = get_new_files(live_files, prev_files)\n",
    "    new_files[\"locale\"] = new_files[\"file_name\"].apply(\n",
    "        lambda x: \"JC\" if x.startswith(\"JC\") else \"NYC\"\n",
    "    )\n",
    "    return new_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_files = get_unprocessed_files()\n",
    "new_files.to_csv(\"new_files_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_citibike_xml_to_df(xml_content):\n",
    "    \"\"\"\n",
    "    Parse the Citibike S3 bucket XML listing into a pandas DataFrame\n",
    "\n",
    "    Args:\n",
    "        xml_content (str): The XML content from the S3 bucket listing\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns 'filename', 'last_modified', 'size_bytes'\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the XML\n",
    "    soup = BeautifulSoup(xml_content, \"xml\")\n",
    "\n",
    "    # Find all Contents elements\n",
    "    contents = soup.find_all(\"Contents\")\n",
    "\n",
    "    # Extract data from each file\n",
    "    file_data = []\n",
    "\n",
    "    for content in contents:\n",
    "        # Get the filename (Key)\n",
    "        key = content.find(\"Key\")\n",
    "        filename = key.text if key else None\n",
    "\n",
    "        # Get the last modified date\n",
    "        last_modified = content.find(\"LastModified\")\n",
    "        last_modified_date = last_modified.text if last_modified else None\n",
    "\n",
    "        # Get the file size\n",
    "        size = content.find(\"Size\")\n",
    "        size_bytes = int(size.text) if size else None\n",
    "\n",
    "        # Add to our data list\n",
    "        if filename:  # Only add if we have a filename\n",
    "            file_data.append(\n",
    "                {\n",
    "                    \"file_name\": filename,\n",
    "                    \"last_modified\": last_modified_date,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(file_data)\n",
    "\n",
    "    # Convert last_modified to datetime\n",
    "    if not df.empty and \"last_modified\" in df.columns:\n",
    "        df[\"last_modified\"] = pd.to_datetime(df[\"last_modified\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citibike",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
